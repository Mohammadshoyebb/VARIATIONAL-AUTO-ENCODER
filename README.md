# VARIATIONAL-AUTO-ENCODER

# Importing Important Libraries

This repository demonstrates the implementation of a Variational Autoencoder (VAE) using TensorFlow and Keras on the MNIST dataset. Below is an overview of the key components and functionalities used in the code:

## Overview

### 1. Importing Libraries

The necessary libraries are imported, including TensorFlow, Keras, Matplotlib for visualization, and others like numpy and tqdm for additional functionalities.

### 2. Loading and Preprocessing MNIST Dataset

The MNIST dataset is loaded using Keras, and the images are normalized to a range of [0, 1] by dividing by 255. This preprocessing step prepares the data for feeding into the VAE model.

### 3. Negative Log Likelihood (NLL) Function

A custom loss function `nll` is defined using Keras backend operations to compute the negative log likelihood, specifically for the Bernoulli distribution.

### 4. KL Divergence Layer

A custom layer `KLDivergenceLayer` is implemented to calculate and add the Kullback-Leibler (KL) divergence to the model loss, which is crucial for the VAE training process. It computes the KL divergence between the learned latent distribution and the prior distribution.

### 5. Encoder Architecture

The encoder part of the VAE is constructed using TensorFlow's Keras API. It consists of convolutional layers followed by dense layers to learn the mean (`z_mu`) and log variance (`z_log_var`) of the latent space.

### 6. Reparameterization Trick

To enable backpropagation through the sampling process, the reparameterization trick is employed. It involves sampling from a unit Gaussian distribution, scaling by the standard deviation (`z_sigma`), and shifting by the mean (`z_mu`).

### 7. Decoder Architecture

The decoder model is designed to reconstruct images from the learned latent space representations. It mirrors the encoder's architecture using transpose convolutional layers (`UpSampling2D`) to upsample the latent vector and reconstruct the image.

### 8. Model Compilation and Training

The VAE model is compiled using the Adam optimizer with the custom `nll` loss function. It is trained on the MNIST training dataset for a specified number of epochs and batch size.

### 9. Model Evaluation

After training, the model's reconstruction performance is evaluated using the test dataset. Mean Squared Error (MSE) is computed between the reconstructed images and the original images from the test set.

### 10. Latent Space Visualization

The latent space representations (`z_test`) of the test dataset are visualized using a scatter plot to understand how different digits are clustered in the learned latent space.

### 11. Manifold Generation

A 2D manifold of digits is generated by sampling from the latent space using the inverse Cumulative Distribution Function (CDF) of the Gaussian distribution. This demonstrates the model's ability to generate new, realistic-looking digit images.

## Conclusion

This README.md provides an overview of implementing a Variational Autoencoder (VAE) using TensorFlow and Keras on the MNIST dataset. It covers the model architecture, training process, evaluation metrics, and visualization techniques used to understand and assess the model's performance in learning a latent representation of digit images.
